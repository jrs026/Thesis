\relax 
\citation{Lafferty01}
\citation{Uszkoreit10}
\citation{wikipedia}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Discriminative Sentence Alignment}{6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:supervised}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Wikipedia as a Comparable Corpus}{6}}
\newlabel{sec:wiki}{{2.1}{6}}
\citation{Adafre06}
\citation{Resnik03}
\citation{Munteanu05}
\citation{Tillmann09a}
\citation{Tillmann09b}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Number of aligned bilingual articles in Wikipedia by language (paired with English).}}{7}}
\newlabel{table:interwiki}{{2.1}{7}}
\citation{Munteanu05}
\citation{Tillmann09a}
\citation{Munteanu05}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Models for Parallel Sentence Extraction}{8}}
\newlabel{sec:models}{{2.2}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Binary Classifiers and Rankers}{8}}
\citation{Munteanu05}
\citation{Gale93}
\citation{Moore02}
\citation{Zhao02}
\citation{Lafferty01}
\citation{Blunsom06}
\citation{Munteanu05}
\citation{Brown93}
\citation{Vogel96}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Sequence Models}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Features}{9}}
\newlabel{sec:features}{{2.2.3}{9}}
\citation{Moore02}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.1}Features derived from word alignments}{10}}
\citation{Smith10}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.2}Distortion features}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.3}Features derived from Wikipedia markup}{11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3.4}Word-level induced lexicon features}{11}}
\citation{Koehn05}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Experiments}{12}}
\newlabel{sec:exp}{{2.3}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Data}{12}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Average precision, recall at 90\% precision, and recall at 80\% precision for each model in all three language pairs. In these experiments, the Wikipedia features and lexicon features are omitted.}}{12}}
\newlabel{table:modelcompare}{{2.2}{12}}
\citation{Ido06}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Average precision, recall at 90\% precision, and recall at 80\% precision for the Ranker and CRF in all three language pairs. ``+Wiki'' indicates that Wikipedia features were used, and ``+Lex'' means the lexicon features were used.}}{13}}
\newlabel{table:featurecompare}{{2.3}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Intrinsic Evaluation}{13}}
\citation{Koehn03}
\citation{Resnik03}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}SMT Evaluation}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces Statistics of the training data size in all three language pairs.}}{15}}
\newlabel{table:mtTrainStats}{{2.4}{15}}
\@writefile{lot}{\contentsline {table}{\numberline {2.5}{\ignorespaces Statistics of the test data sets.}}{16}}
\newlabel{table:mtTestStats}{{2.5}{16}}
\citation{OchMert03}
\@writefile{lot}{\contentsline {table}{\numberline {2.6}{\ignorespaces BLEU scores of MT systems under various training and test conditions. The final BLEU score from minimum error rate training is in the first column; two additional columns are BLEU scores on held-out test sets. For training data conditions including the extracted Wikipedia sentences, the parenthesized values indicate the absolute BLEU difference against the corresponding system without Wikipedia extracts.}}{17}}
\newlabel{table:mtTestResults}{{2.6}{17}}
\citation{Papineni02}
\citation{Resnik03}
\citation{Huang05}
\citation{Shi06}
\citation{Uszkoreit10}
\citation{Uszkoreit10}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Comparable documents from the Web}{18}}
\citation{Uszkoreit10}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Data collection}{19}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.1}Annotation Tool}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces The annotation interface for sentence alignment.  }}{20}}
\newlabel{fig:google_annotate}{{2.1}{20}}
\citation{Eisner02}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1.2}Data Collection Results}{21}}
\@writefile{lot}{\contentsline {table}{\numberline {2.7}{\ignorespaces Statistics on the types of $n:m$ alignments found in the annotated data.}}{21}}
\newlabel{table:merge_stats}{{2.7}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Monotonic alignment model}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The discriminative model for monotonic sentence alignment. The highlighted path represents a possible alignment between the two documents.}}{22}}
\newlabel{fig:mono_disc}{{2.2}{22}}
\citation{Eisner02}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2.1}Features}{24}}
\newlabel{sec:mono_feats}{{2.4.2.1}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Results}{24}}
\@writefile{lot}{\contentsline {table}{\numberline {2.8}{\ignorespaces Precision, recall and F1 score measured on a held out set of aligned Japanese-English document pairs.}}{25}}
\newlabel{table:google_results}{{2.8}{25}}
\@setckpt{chapter02-supervised}{
\setcounter{page}{26}
\setcounter{equation}{0}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{2}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{2}
\setcounter{table}{8}
\setcounter{parentequation}{0}
\setcounter{r@tfl@t}{0}
\setcounter{NAT@ctr}{0}
}
