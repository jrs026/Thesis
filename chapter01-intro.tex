\chapter{Introduction}
\label{chap:intro}

Statistical machine translation (SMT) systems are trained using a large collection of translated
sentence pairs known as a parallel corpus. Common sources of parallel data include
parliament proceedings, books, and news articles.
For some language pairs, we have large amounts of this data. For example, the Canadian
Hansards are parliamentary proceedings that give us millions of words of
French/English parallel data \citep{Germann01}. Similarly, the proceedings of
European Union parliament are a source of parallel data for all of the languages
of its member states \citep{Koehn05}. Outside of these government sources, we
also have large collections of parallel data from news agencies for some
language pairs, such as Chinese/English \citep{Ma05}.
However, for most language pairs, we have little to no data available.
In addition, even when parallel
data is available, it often does not match the domain of the data you wish to
translate, which hurts translation quality \citep{Munteanu05}.
\adlbr{This section needs some examples to make it crystal clear what you're
talking about, even for a non-NLP person. Show an example in news or government, 
and one of your other domains (wikipedia, travel, etc.)} 

The creation of new parallel corpora can be expensive, especially when bilingual
speakers are rare for the language pair of interest. \citet{Germann01a}
investigated the costs of collecting enough data to build Tamil/English SMT
system. They found that professionally translated data would cost $\$0.36$ per
word. \citet{Germann01a} and others \citep{Zaidan11} were able to reduce the
cost of creating parallel corpora by looking to non-professional translators,
but the cost is still around $\$0.10$ per word.
In order to acquire more parallel data without this cost,
researchers have looked to multilingual corpora which share some content across languages,
but are not directly translated. Such corpora are referred to as comparable
corpora, and examples include multilingual news feeds \citep{Munteanu05},
Wikipedia articles \citep{Adafre06,Smith10}, and the Web
\citep{Resnik99,Nie99,Chen00}. 
%Most work in extracting parallel sentences from
%these corpora assumes an initial bilingual dictionary or an existing parallel
%corpus.

Comparable corpora is a broad term---\citet{Fung04a} give a more
fine-grained categorization of multilingual corpora:
%TODO: Make sure this is quoted properly
\begin{enumerate}
\item Parallel corpus: A sentence-aligned corpus containing bilingual
translations of the same document. (Curated parallel corpora)
\item Noisy parallel corpus: A corpus containing non-aligned sentences that are
nevertheless mostly bilingual translations of the same document. (Hansards,
Europarl, most ``parallel'' corpora)
\item Comparable corpus: A corpus of non-aligned and non-translated documents
which are topic-aligned. (Wikipedia)
\item Quasi-comparable corpus: A multilingual corpus which is not
sentence-aligned, translated, or topic-aligned. (the Web, multilingual news feeds)
\adlbr{I don't even know what this means. Does it serve your larger point to mention this?}
\NoteJS{The purpose of these categories is just to show that very different
corpora are called comparable, and they require very different methods to mine
for parallel data. I added examples to each category, but I'm not sure if that
helps with the confusion.}
\end{enumerate}
As comparable corpora vary greatly in their structure, different methods for finding
parallel sentences are used in each.

Even corpora which are generally considered as parallel require some amount of
processing to find parallel sentences. 
A translator may chose to translate a compound sentence as two sentences, or
vice-versa, so naively assuming that sentences are aligned in order will not
work.
Also, there may be large insertions or deletions of sentences even in curated
sources of parallel data, such as the Canadian Hansards \citep{Gale93,Chen93}.
Sentence-aligning these corpora does not require existing parallel data or a
bilingual dictionary for the language pair of interest. Instead, the structure
of the documents and the lengths of the sentences are used to determine the
sentence alignment. For comparable corpora which are topic-aligned but not
directly translated, lexical information must be used to determine which
sentence pairs should be aligned \citep{Munteanu05}. When comparable corpora are
not topic-aligned, other signals are exploited to find plausible document
alignments \citep{Resnik03}.

We will examine a representative set of comparable corpora: the Web, Twitter,
and Wikipedia; describe the different signals used to identify parallel data,
and demonstrate how extracted parallel data from these corpora improve SMT
performance across several language pairs and domains. First, we scale up
previous Web mining methods \citep{Resnik03} to several terabytes of data. We
also present a novel mining approach for Twitter, making use of metadata unique
to the microblogging medium. Finally, we introduce a new sentence alignment
model for mining parallel data from Wikipedia which takes advantage of its
fine-grained topic alignment.\adlbr{I am not sure about this particular order.
Let's discuss soon.}

\section{What counts as parallel?}
This work is centered around finding parallel data---bilingual sentence pairs
which convey the same meaning. Unfortunately, it is extremely difficult, if not
impossible, to determine whether or not two sentences in different languages
have the same meaning. One language may contain gender markings that the other
does not, or the connotation of a word may be difficult to express in another
language. Examples of this problem are explored in depth by \citet{Kay97}. 
Even ignoring the cross-lingual issues, comparing the meaning of two sentences
in the same language is still quite difficult---SMT evaluation metrics
\citep{Papineni02,Banerjee05,Snover06} must address this problem.
\adlbr{I like this, but note that this stands somewhat in opposition to the Fung
paper you talk about above. This gives a very functional description of parallelism:
it's anything that makes the BLEU score go up. Of course your evaluations might
be somewhat insensitive to errors in detecting parallelism---we don't know if
they care more about precision or recall. I think you need to address this, 
probably empirically.}
\NoteJS{I don't understand how this is in conflict with the Fung paper. I only
quote that to talk about different types of comparable corpora.}

When evaluating methods for finding parallel data, we can either measure
intrinsic or extrinsic performance. Intrinsic evaluation directly measures the
quantity and quality of parallel data we extract, while extrinsic evaluation is
only concerned with how the new parallel data improves SMT performance.
In order to perform intrinsic evaluation, we need some criteria for determining whether or not a bilingual
sentence pair is parallel. This is easy if we use parallel data, but
it is preferable to evaluate our methods on the same corpora that we are
extracting data from. When designing the criteria for judging parallel
sentences, we focus on our extrinsic goal: improving SMT performance. If a sentence pair
is likely to improve performance when added to our SMT system's training data,
we would like to extract it. The details of our annotation criteria can be found
in Chapter \ref{chap:supervised}, but in all cases they are motivated by SMT
performance. To understand what will influence performance, we need to
understand modern SMT systems.

\section{Statistical Machine Translation}
While machine translation has been around in some form for many decades
\citep{Locke55}, statistical machine translation began with the work of
\citet{Brown88,Brown90,Brown93}. SMT systems have evolved since then, most notably moving from
word-based systems to phrase-based \citep{Koehn03}. Several newer systems have
been developed, focusing mostly on incorporating syntax into the translation
model \citep{Chiang05,Quirk05,Liu06,Galley06}. These systems all share some key
characteristics in how they use parallel data:

\begin{enumerate}
\item A large collection of parallel sentences are used as training data.
\item For each parallel sentence, word-to-word correspondences are found. This
step is called word-alignment, and it is usually done with unsupervised methods
\citep{Brown93,Vogel96}.
\item Pairs of phrases, or other multi-word units, are extracted from the
word-aligned sentence pairs to form a translation model.\adlbr{Example.}
\item A language model is created from large amounts of monolingual data in the
``target'' language (the language which text is translated into). This includes
the target side of the parallel training data.
\end{enumerate}

There are additional details in each model, but the main effects of adding new
parallel data are additional inputs to the translation and language models.
\adlbr{The language model argument is weaker here.}

\section{Evaluation Pipeline}
Our evaluation setup is identical across chapters---we start with {\em initial}
data that includes some standard parallel and monolingual corpora commonly used for 
translation. We also have {\em extracted} parallel data that we find in a comparable
corpus. Table \ref{tab:exp_setup} describes how we use this data to measure SMT
improvements:

\begin{table}
\begin{center}
\begin{tabular}{|c||c|c|}
\hline
& Parallel & Monolingual \\
\hline
Baseline & Initial & Initial + Extracted \\
\hline
Experimental & Initial + Extracted & Initial + Extracted \\
\hline
\end{tabular}
\end{center}
\label{tab:exp_setup}
\caption{Parallel and monolingual data used in our SMT experiments.}\adlbr{This table seems a little suspect. Why would you use initial+extracted for the baseline results? Realistically, you could have a baseline built from a large monolingual text of any kind (Maybe even in-domain). The line you list as baseline here makes sense to tease apart whether the differences come from TM or LM (that's good), but should probably include an additional baseline.}
\NoteJS{Another baseline without the extracted target side in the language model
wouldn't hurt, but I don't think it's crucial and it's not available for the
Wikipedia experiments. Everything I've done so far has used this setup. It might be something I include in some experiments.}
\end{table}

In both the baseline and experimental conditions, we include the target side of
the extracted parallel sentences in the monolingual training data. We do this to
ensure that any increase in performance is coming from the parallel data. It
would be simple to add monolingual text from a comparable corpus to an SMT
system.\adlbr{This is probably also a good baseline.}

In all experiments, the BLEU metric \citep{Papineni02} is used to evaluate SMT
performance. The BLEU metric combines $n$-gram precision (the percentage of
$n$-grams in the hypothesis translation which are found in the reference) with a
brevity penalty.
The initial data, test sets, and other details vary by experiment.


\section{Sentence Alignment}\adlbr{I agree that this probably does not fit here. The question is: what does? I think you might want to say something about prior art here, or otherwise fit in relevant parts of your lit review. Logically, a reader that has arrived at this point in your dissertation should understand the problem you're trying to solve at a high level, and might wonder what other approaches have been taken.}
In this section, we will describe our task and notation.
We will view both parallel corpora alignment and the extraction of parallel
sentences from comparable corpora as an alignment task. In either type of
alignment we are given a set of bilingual document pairs in {\em source} and {\em
target} languages. When performing parallel corpora alignment, these document
pairs will correspond to each other very strongly, while in the case of
comparable corpora, some these document pairs may contain no parallel sentences.
\citet{Munteanu05} take their document pairs from news stories published at
roughly the same time, while \citet{Adafre06,Smith10} use entries from
Wikipedia that are on the same topic (Figure \ref{fig:wiki} gives and example).
The task of finding comparable document pairs is not addressed in this work.

\begin{figure*}[ht]
\includegraphics[width=\textwidth]{images/wiki.jpg}
\caption{An example of a Spanish/English document pair from Wikipedia.\adlbr{I think you want this example to appear in your comparable corpus section.}}
\label{fig:wiki}
\end{figure*}

Each document pair contains a sequence of source sentences (denoted by ${\bf
S}$) and target sentences (denoted by ${\bf T}$). Individual source and target
sentences are referred to by $S$ and $T$ respectively. Similarly, we refer to
the words within source and target sentences with the lowercase $s$ and $t$. We
borrow the notation of \citep{Och03} for describing alignments between sentences
as subsets of the Cartesian product of sentence positions. Sentence alignments
are referred to with the uppercase $A$, and word alignments with the lowercase
$a$.

The goal of sentence alignment is to identify which sentence pairs in the
bilingual document pairs are parallel. We view this as a retrieval task for
parallel sentence pairs, and so when annotated sentence alignments are present,
we can compute precision, recall, and F-measure.
